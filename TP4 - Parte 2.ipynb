{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f354d2c2-9403-4d64-8a0b-6d2e83291c25",
   "metadata": {},
   "source": [
    "Big Data - TP 4 Parte 2. Sofia Ellenberg, Sophie Schulzen, Vicente Zervino \n",
    "\n",
    "Construccion de funciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7989dcd7-b5af-41f8-9531-f337b483a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio 1 : \n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score\n",
    "\n",
    "\n",
    "#Escribimos la funcion evalua_metodo con un modelo como argumento y los datos de entrenamiento y testeo. Luego, ajustamos el modelo con los datos.\n",
    "#Por ultimo, calculamos la matriz de confusion, las curvas ROC, los valores de AUC y accuracy score. \n",
    "\n",
    "\n",
    "def evalua_metodo(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    MAT_CONF = confusion_matrix(y_test, y_pred) #Matriz de confusion\n",
    "    ACCURACY = accuracy_score(y_test, y_pred) # Accuracy score\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_prob)  # Curva roc\n",
    "    AUC_ROC = auc(fpr, tpr) # AUC\n",
    "\n",
    "#Matriz de confgusion \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues')\n",
    "    plt.title('Matriz de Confusión')\n",
    "    plt.xlabel('Predicción')\n",
    "    plt.ylabel('Real')\n",
    "    \n",
    "#Curva ROC\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(fpr, tpr, lw=2, color= 'blue', label=f'Curva ROC (AUC = {AUC_ROC:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Falsos Positivos')\n",
    "    plt.ylabel('Verdaderos Positivos')\n",
    "    plt.title('Curva ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "#Creamos un dccionario que devuelva las metricas.\n",
    "    METRICAS = {\n",
    "        'confusion_matrix': MAT_CONF,\n",
    "        'accuracy': ACCURACY,\n",
    "        'roc_auc': AUC_ROC,\n",
    "        'roc_curve': (fpr, tpr)\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a7815be-1f84-4cf9-9409-6610f8b4f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "522b31b7-0191-4f58-91f6-4b366ecf565b",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Ejercicio 2: \n",
    "\n",
    "#Ahora escribimos la funcion cross_validation que haga cross validation con k iteraciones. En cad auna llamara a la funcion del inciso anterior pero para las k partiicones. \n",
    "#Como argumento recibira, el modelo, el valor de k y x e y como dataset. #Hacemos las particiones usando la funcion Kfold.\n",
    "\n",
    "def cross_validation(model, k, X, y):\n",
    "    KFOLD = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    ACCURACY_SCORES = []\n",
    "    AUC_SCORES = []\n",
    "\n",
    "    for train_index, test_index in KFOLD.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        METRICAS = evalua_metodo(model, X_train, y_train, X_test, y_test)\n",
    "        ACCURACY_SCORES.append(metrics['accuracy'])\n",
    "        AUC_SCORES.append(metrics['roc_auc'])\n",
    "    \n",
    "    accuracy_promedio = np.mean(ACCURACY_SCORES)\n",
    "    auc_promedio = np.mean(AUC_SCORES)\n",
    "    \n",
    "    print(f'Accuracy Promedio: {accuracy_promedio:.4f}')\n",
    "    print(f'AUC-ROC Promedio: {auc_promedio:.4f}')\n",
    "    \n",
    "    return accuracy_promedio, auc_promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d510e5a-d26a-491e-abb0-7fed249ee06a",
   "metadata": {},
   "source": [
    "Ejercicio 3\n",
    "Escribimos la funcion evalua_config que reciba una lista de configuraciones de hiperparámetros, donde cada configuración será un diccionario de Python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42579ac3-0ac0-4e25-9767-449205079d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio 3 \n",
    "def evalua_config(model_class, hyperparameter_configs, k, X, y):\n",
    "    mejor_configuracion = None #Tenemos que inicializar la variable para luego poder almacenar la mejor configuracion y el menor error.\n",
    "    error_minimo = float('inf') \n",
    "\n",
    "#Como dice la consgna iteramos hiperparámetros\n",
    "    for configuracion in hyperparameter_configs:\n",
    "        print(f\"Evaluar la configuracion: {configuracion}\")\n",
    "        \n",
    "        modelo = model_class(**configuracion)\n",
    "#Obtenemos el error promedio con cross validation usamdo el ECM\n",
    "        errores = []\n",
    "        for train_index, test_index in KFOLD.split(X):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            error = mean_squared_error(y_test, y_pred)\n",
    "            errores.append(error)\n",
    "        \n",
    "        error_promedio = np.mean(errores)\n",
    "\n",
    "\n",
    "        if error_promedio < error_minimo: #Por si encontramos un error menor \n",
    "            error_minimo = error_promedio\n",
    "            mejor_configuracion = configuracion\n",
    "\n",
    "#Printiamos la mejor configuración que hayamos encontrado y el menor error\n",
    "    print(\"La mejor configuración es:\", mejor_configuracion)\n",
    "    print(\"Error mínimo:\", error_minimo)\n",
    "    \n",
    "#La funcion nos devuelve la configuracion que genere menor error.\n",
    "    return mejor_configuracion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafb0501-5187-4045-9536-116e87069f02",
   "metadata": {},
   "source": [
    "Ejercicio 4:\n",
    "Escribimos una funcion llamada evalua_multiples_metodos. Usamos la funcion evalua_config para optimizar el λ de la regularizacion.\n",
    "\n",
    "Obtenemos una tabla donde las columas son las metricas (de la fc evalua_metodo) y las filas son los modelos (con su configuracion de hiperparametros asociada) que corrimos antes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4eec9175-7e72-4438-9591-16a6212e5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from statistics import mean\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bdb5e85-6927-4f78-ab81-f467584049ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejercicio 4\n",
    "\n",
    "#Usamos las funciones de los ejercicios anteriores. \n",
    "# Función para evaluar múltiples métodos. \n",
    "\n",
    "def evalua_multiples_metodos(X_train, y_train, X_test, y_test):\n",
    "    results = []\n",
    "    \n",
    "# Regresión Logística\n",
    "    logreg_hyperpar = [\n",
    "        {'penalty': 'l1', 'C': 0.1},\n",
    "        {'penalty': 'l2', 'C': 0.01},\n",
    "        {'penalty': 'none'}\n",
    "    ]\n",
    "    mejor_configuracion_logreg = evalua_config(LogisticRegression, logreg_hyperpar, 5, X_train, y_train)\n",
    "    logreg_model = LogisticRegression(**mejor_configuracion_logreg)\n",
    "    logreg_metricas = evalua_metodo(logreg_model, X_train, y_train, X_test, y_test)\n",
    "    results.append({'Modelo': 'Reg Logística', 'Configuración': mejor_configuracion_logreg, **logreg_metricas})\n",
    "    \n",
    "    # Análisis de Discriminante Lineal\n",
    "    ADL_model = LinearDiscriminantAnalysis()\n",
    "    ADL_metricas = evalua_metodo(ADL_model, X_train, y_train, X_test, y_test)\n",
    "    results.append({'Modelo': 'Análisis Discriminante Lineal', 'Configuración': None, **ADL_metricas})\n",
    "    \n",
    "    # KNN\n",
    "    knn_hyperpar = [\n",
    "        {'n_neighbors': 3, 'weights': 'uniform'},\n",
    "        {'n_neighbors': 5, 'weights': 'distance'}\n",
    "    ]\n",
    "    mejor_configuracion_knn = evalua_config(KNeighborsClassifier, knn_hyperpar, 5, X_train, y_train)\n",
    "    knn_model = KNeighborsClassifier(**mejor_configuracion_knn)\n",
    "    knn_metricas = evalua_metodo(knn_model, X_train, y_train, X_test, y_test)\n",
    "    results.append({'Modelo': 'KNN', 'Configuración': mejor_configuracion_knn, **knn_metricas})\n",
    "    \n",
    "#Por ultimo, convertimos los resultados a una base de datos \n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a162ecce-7221-43ba-baa2-5015c14c6889",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
